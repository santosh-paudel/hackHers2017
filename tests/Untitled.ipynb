{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Tas.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8d4b17d8a882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextToWrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfaceRectangle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfaceRectangle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'top'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m \u001b[0mread_and_classifyImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-8d4b17d8a882>\u001b[0m in \u001b[0;36mread_and_classifyImage\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_and_classifyImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m    \u001b[0mpathToImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Tas.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m    \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpathToImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m        \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Tas.jpg'"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[131]:\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import cv2\n",
    "import operator\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# In[133]:\n",
    "\n",
    "_url = 'https://westus.api.cognitive.microsoft.com/emotion/v1.0/recognize'\n",
    "_key= 'a9676e1d0c594525954aab7dc77e75d0'\n",
    "\n",
    "\n",
    "# In[148]:\n",
    "\n",
    "def processRequest( json, data, headers, params ):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper function to process the request to Project Oxford\n",
    "\n",
    "    Parameters:\n",
    "    json: Used when processing images from its URL. See API Documentation\n",
    "    data: Used when processing image read from disk. See API Documentation\n",
    "    headers: Used to pass the key information and the data type request\n",
    "    \"\"\"\n",
    "\n",
    "    retries = 0\n",
    "    result = None\n",
    "\n",
    "    while True:\n",
    "\n",
    "        response = requests.request( 'post', _url, json = json, data = data, headers = headers, params = params )\n",
    "\n",
    "        if response.status_code == 429: \n",
    "\n",
    "            print( \"Message: %s\" % ( response.json()['error']['message'] ) )\n",
    "\n",
    "            if retries <= _maxNumRetries: \n",
    "                time.sleep(1) \n",
    "                retries += 1\n",
    "                continue\n",
    "            else: \n",
    "                print( 'Error: failed after retrying!' )\n",
    "                break\n",
    "\n",
    "        elif response.status_code == 200 or response.status_code == 201:\n",
    "\n",
    "            if 'content-length' in response.headers and int(response.headers['content-length']) == 0: \n",
    "                result = None \n",
    "            elif 'content-type' in response.headers and isinstance(response.headers['content-type'], str): \n",
    "                if 'application/json' in response.headers['content-type'].lower(): \n",
    "                    result = response.json() if response.content else None \n",
    "                elif 'image' in response.headers['content-type'].lower(): \n",
    "                    result = response.content\n",
    "        else:\n",
    "            print( \"Error code: %d\" % ( response.status_code ) )\n",
    "            print( \"Message: %s\" % ( response.json()['error']['message'] ) )\n",
    "\n",
    "        break\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "# In[168]:\n",
    "\n",
    "def read_and_classifyImage():\n",
    "   pathToImage = 'Tas.jpg'\n",
    "   with open( pathToImage, 'rb' ) as f:\n",
    "       data = f.read()\n",
    "\n",
    "   headers = dict()\n",
    "   headers['Ocp-Apim-Subscription-Key'] = _key\n",
    "   headers['Content-Type'] = 'application/octet-stream'\n",
    "\n",
    "   json = None\n",
    "   params = None\n",
    "\n",
    "   result = processRequest( json, data, headers, params )\n",
    "\n",
    "   #this part of the code grabs the maximum value emotion and emotion-rank\n",
    "   x=result[0]['scores'] #get the list of possible emotion and their rank\n",
    "   print(result[0]['scores'])\n",
    "   keys=[] #dummy dictionary\n",
    "   values=[]\n",
    "   for key,value in x.items():\n",
    "       keys.append(key)\n",
    "       values.append(value)\n",
    "   max_value=max(values)\n",
    "   max_values=list((math.ceil((max(values)*10)),keys[values.index(max_value)]))\n",
    "   print(max_values)\n",
    "   if result is not None:\n",
    "    # Load the original image from disk\n",
    "    data8uint = np.fromstring( data, np.uint8 ) # Convert string to an unsigned int array\n",
    "    img = cv2.cvtColor( cv2.imdecode( data8uint, cv2.IMREAD_COLOR ), cv2.COLOR_BGR2RGB )\n",
    "\n",
    "    renderResultOnImage( result, img )\n",
    "\n",
    "    ig, ax = plt.subplots(figsize=(15, 20))\n",
    "    ax.imshow( img )\n",
    "\n",
    "def renderResultOnImage(result,img):\n",
    "    \n",
    "    \"\"\"Display the obtained results onto the input image\"\"\"\n",
    "    \n",
    "    for currFace in result:\n",
    "        faceRectangle = currFace['faceRectangle']\n",
    "        cv2.rectangle( img,(faceRectangle['left'],faceRectangle['top']),\n",
    "                           (faceRectangle['left']+faceRectangle['width'], faceRectangle['top'] + faceRectangle['height']),\n",
    "                       color = (255,0,0), thickness = 5 )\n",
    "\n",
    "\n",
    "    for currFace in result:\n",
    "        faceRectangle = currFace['faceRectangle']\n",
    "        currEmotion = max(currFace['scores'].items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "\n",
    "        textToWrite = \"%s\" % ( currEmotion )\n",
    "        cv2.putText( img, textToWrite, (faceRectangle['left'],faceRectangle['top']-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1 )\n",
    "\n",
    "read_and_classifyImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
